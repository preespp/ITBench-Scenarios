---
- name: Get pods for target workload
  kubernetes.core.k8s_info:
    kubeconfig: "{{ faults_cluster.kubeconfig }}"
    kind: Pod
    namespace: "{{ spec.workload.namespace }}"
    label_selectors:
      - app.kubernetes.io/name={{ spec.workload.name }}
  register: workload_pods

- name: Select node hosting target workload
  set_fact:
    target_node: "{{ workload_pods.resources[0].spec.nodeName }}"

- name: Label the node as target for resource hog
  kubernetes.core.k8s:
    kubeconfig: "{{ faults_cluster.kubeconfig }}"
    resource_definition:
      apiVersion: v1
      kind: Node
      metadata:
        name: "{{ target_node }}"
        labels:
          node-role.kubernetes.io/app: "true"
    state: present

- name: Deploy resource hog on target node
  kubernetes.core.k8s:
    kubeconfig: "{{ faults_cluster.kubeconfig }}"
    resource_definition:
      apiVersion: apps/v1
      kind: Deployment
      metadata:
        name: fake-resource-hog
        namespace: "{{ spec.workload.namespace }}"
      spec:
        replicas: 1
        selector:
          matchLabels:
            app: fake-resource-hog
        template:
          metadata:
            labels:
              app: fake-resource-hog
          spec:
            nodeSelector:
              node-role.kubernetes.io/app: "true"
            containers:
              - name: stress-container
                image: progrium/stress
                args: ["--cpu", "8", "--io", "4", "--vm", "2", "--vm-bytes", "512M"]
